\documentclass[11pt]{article}

\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{array}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{color}
\usepackage{mwe}
\usepackage{caption}
\usepackage{float}
\usepackage{hyperref,bookmark}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{rotating}

\usepackage{algorithm,algpseudocode,float}
\usepackage{lipsum}
% \usepackage{subfigure,subcaption}
%\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\makeatletter
\newenvironment{breakablealgorithm}
  {% \begin{breakablealgorithm}
   \begin{center}
     \refstepcounter{algorithm}% New algorithm
     \hrule height.8pt depth0pt \kern2pt% \@fs@pre for \@fs@ruled
     \renewcommand{\caption}[2][\relax]{% Make a new \caption
       {\raggedright\textbf{\ALG@name~\thealgorithm} ##2\par}%
       \ifx\relax##1\relax % #1 is \relax
         \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##2}%
       \else % #1 is not \relax
         \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##1}%
       \fi
       \kern2pt\hrule\kern2pt
     }
  }{% \end{breakablealgorithm}
     \kern2pt\hrule\relax% \@fs@post for \@fs@ruled
   \end{center}
  }
\makeatother



\renewcommand\algorithmicrequire{\textbf{INPUT:}}
\renewcommand\algorithmicensure{\textbf{OUTPUT:}}

\definecolor{Title}{RGB}{0,84,126}

\newenvironment{conditions*}
  {\par\vspace{\abovedisplayskip}\noindent
   \tabularx{\columnwidth}{>{$}l<{$} @{${}={}$} >{\raggedright\arraybackslash}X}}
  {\endtabularx\par\vspace{\belowdisplayskip}}

\begin{document}
\begin{titlepage}
    \centering
        \centering
        \includegraphics{UoNTitle.png}
   

    \Large{\textcolor{Title}{Reducing the cost using Battery Energy Storage System when Electricity Price fluctuates}}\\
    \vspace{1.5cm}



    Submitted April 2023, in partial fulfillment of the conditions for the award of the degree BSc Computer Science with Artificial Intelligence
    \vspace{1.5cm}

    \textcolor{Title}{20215708}\\
    School of Computer Science\\
    The University of Nottingham\\
    \vspace{1cm}
    I hereby declare that this dissertation is all my own work, except as indicated in the text:\\
    \vspace{1cm}
    \Large{\textcolor{Title}{\textbf{Signature:} }}\\
    \vspace{0.5cm}
    \Large{\textcolor{Title}{\textbf{Date:} 24/04/2023}}\\
    \vspace{2.5cm}
    I hereby declare that I have all necessary rights and consents to publicly distribute this dissertation via the University of Nottingham's e-dissertation archive
    
\end{titlepage}


\hypersetup{
        colorlinks=false,
        linkcolor=black,
        filecolor=blue,      
        urlcolor=blue,
        citecolor=black,
}
\begin{abstract}
    \noindent Multiple factors like economic reason and social reason contributes to the need to adjust the energy import and export behavior of customers with Battery Energy Storage System(BESS). Hence, it is essential to apply some algorithms to maximize the benefit of the BESS for customers which is called the BESS control problem. Hence, studying and comparing these algorithms is the theme of this dissertation.\newline\newline
    The project contributes mainly two novelties to the field: comparing algorithms in-depth to get a complete understanding of the algorithms and applying some novel algorithms to the BESS problem. The project analyses the algorithm from the quality of the solution, run-time and memory usage. Additionally, this dissertation will implement some novel algorithms.\newline\newline
    

\end{abstract}
\newpage
\section*{Acknowledgment}
\addcontentsline{toc}{section}{Acknowledgment} % 将致谢添加到目录中
During the project, my supervisor Geert De Maere has helped me a lot. For instance, at the beginning of the project, when I felt confused about the project, he gave me some guidance which gave the whole project a good start. I feel grateful for his assistance and guidance. \newline\newline
Additionally, I wanna convey my appreciation to Eskil Sulen Gjerde and Muhammad Farooq. They have allowed me to refer to their work and provided me with their paper. \newpage
\begin{center}
\tableofcontents
\end{center}
\newpage

\section{Introduction}
The wholesale electricity price has been rapidly increasing, for example, the electricity price in the first half of 2022 was twice the average from 2016 to 2021 during the first half of the year in Europe \cite{price} multiple factors could lead to this. First, since Covid lockdown and trade restrictions, the demand for fossil fuel energy surpassed the supply and further caused an increase in oil prices. Moreover, the Russia-Ukraine war worsens the situation due to the sanctions imposed on Russia. This sanction resulted in a disruption in the energy supply to European countries and make the gas price rise. Both of them contributed to the energy crisis in Europe, consequently, leading to electricity prices increasing \cite{energycrisis}. \newline\newline
Additionally, people became more and more aware of the problem of air pollution and global warming caused by traditional energy sources. Indoor and outdoor air pollution is responsible for more than two million illnesses cases and death cases, which may have a terrible impact on the economy and security of nations. Furthermore, global warming both creates disease problems like heat stress and exacerbates the severity of environmental problems like tropical storms. Worse still, the location of the suitable agricultural place will be changed, and the ecosystem will be destructed as well as animal habitats \cite{newenergy}. Hence, to avoid the appalling consequences caused by the usage of conventional energy sources, people tried to replace them with clean energy. However, clean energy like wind and solar power is intermittent, which means its power output instability makes it hard to match electricity demand \cite{instable}. Hence, Battery Energy Storage System(BESS) can be used to overcome this shortage by collecting energy during low-demand periods and injecting the energy when needed \cite{BESSandClean}. \newline\newline
BESS is composed of batteries, a control and power conditioning system, and the rest of the plant. The rest of the plant is aimed at protecting batteries and control and power conditioning systems. The batteries are made of stacked cells. The most important features of the battery are its energy capacity and power rating. Furthermore, the batteries used in BESS also have different types with different materials and working modes. Another component Controls and Power conditioning systems (C-PCS) are critical in BESS, which is also the field that this paper will focus on. C-PCS interfaces the batteries to the loads and controls the behavior of the batteries-charge or discharge and the charging rate. This component can be used to enhance power system reliability and power quality \cite{introduction}. \newline\newline
The price of the battery and the electricity price tariff structure also make BESS more advantageous. The lithium-ion battery price has reduced by 97\% since 1991, which enables the cost of renewable technologies to be cheaper than fossil fuels \cite{cheapbattery}. Besides the battery price, the tariff structure is another reason to deploy BESS. Many countries including the UK \cite{uktou} adopt a time-of-use (TOU) tariff policy due to the shortage of energy. TOU is a kind of structure that stipulate peak hours with higher electricity price and off-peak hours with cheap price during the day. This gives BESS room to operate, which means BESS can charge at periods when the price is cheap and discharge at periods with higher prices. As a consequence, the entire load is still met with lower expenses \cite{whytou}. \newline\newline
The BESS control problem becomes a significant problem in many aspects. As illustrated above, because of the rapidly increasing energy price, millions of people have been impacted by the price, especially those with lower-income households. For instance, it will cost the poorest 20\% of families an extra £1,000-1,100 \cite{keya}. Apart from reducing the electricity cost, BESS can also be applied in many other different applications. They can act as an uninterruptible power supply and reduce the negative impact of downtime during an electricity grid failure which is vital to equipment like servers that require a high level of continuous power supply. BESS can also be used to build independent microgrids in remote areas which can help people live in such places and avoid heavy costs \cite{function}.\newline\newline
\noindent Furthermore, current power systems face technical limitations, such as unpredictable renewable energy sources and high load demands, which create economic inefficiencies in the deregulated electric market \cite{grid}. As a result, energy storage technology presents promising opportunities for various stakeholders \cite{optimisation}. To address these challenges, the battery energy storage system (BESS) has been developed and implemented. This system is composed of batteries, control and power conditioning systems, and protective devices \cite{divya2009battery}. The BESS is connected to the AC distribution grid through a converter and can serve as an end-user load to reduce energy costs during periods of low prices and enable load shifting during peak demand periods, thereby improving grid stability \cite{bessgrid}. Using this system, low-income households can also reduce their energy burden and contribute to overall power system improvement by taking advantage of predicted electricity prices and managing their loads more efficiently.
\subsection{Aims and Processes}
The project aims to compare different methods in depth, including success rate, percentage of global optimal found, runtime, and memory usage comparison. Such comparisons can rarely be found in other papers. Except for comparisons, this paper similarly focuses on novelty. some methods that have not been applied to the BESS prediction control model are also implemented in the project, to find out if there is a better method. \newline\newline
At the beginning of the project, previous simple methods MILP and DP (with or without pruning strategies) are implemented to get familiar with the BESS problem and prepared for the next algorithms. Afterwards, implementing some novel methods which has not been applied to the BESS prediction problem before. First, the rolling horizon approach and its improved version based on different methods is implemented to find if the information is limited, whether the performance of the algorithms would change. Then the information is further limited, only previous data is available. Hence, rule-based heuristic is implemented though there are some previous work on this problem. However, new rules are designed for the problem. Finally, a prediction component is created and added to the rule heuristic which attempts to improve the performance. \newline\newline
After implementing all the algorithms, the project runs them for 20 times on different size of the dataset and record all the results from different criteria. Finally, a deep comparison can be done with these results. 

\newpage
\section{Motivation}
Due to the practical datasets and the well-structured of the BESS control problem, correct answers can be generated through the application of an appropriate algorithm. Hence, comparing different approaches and strategies and applying novel algorithms become easier work.\newline\newline
Currently, there are several existing approaches and strategies, such as Mixed Integer Linear Programming, in the previous papers that can be applied to optimize the BESS control problem which means providing sequential control operations to manipulate BESS for the purpose of exploring the global optima. However, some of them only focus on the performance of one exact approach, they have emphasized the work mode of the algorithm and how close their models come to reality. Consequently, people are confused when there are several different approaches to the same problem with no idea which one performs better, although these algorithms have been studied in detail and comprehensively. Other existing algorithms have been studied and compared in other papers under the same circumstance of the problem. Nevertheless, these papers either didn't compare them in-depth, or the methods they have put together are few. That's one of the motivations for this paper, to do some research on the deep comparison between those existing algorithms. \newline\newline
Additionally, some approaches that have not been applied to this problem but are famous in other fields will also be implemented and compared in this paper. Some of these algorithms such as rule-based heuristics have proven their efficiency and effect on other problems which are similar in structure to the problems this paper is going to study. Other algorithms like rolling horizon algorithms are suitable for time series problem including the BESS control model. Applying these novel approaches to the BESS prediction control model is another motivation for this paper.\noindent
The final motivation for studying this topic is the practical and economic factors mentioned in the introduction. After finding the most feasible algorithm that combines all aspects, BESS can be better deployed in commercial or civil scenarios. Hence, they can help reduce the electricity cost for those who will use BESS in a shorter time and with less memory. With a completed, professional model, customers no longer need to operate or set the parameters and instructions themselves, the model will help them to deal with the complicated data of loads and various electricity tariff structures, which may make BESS better promoted. Moreover, the grid can ease the burden of imbalanced loads between peak and off-peak times and the waste of energy when the demand is far away from the generated energy during off-peak times. All of these improvements could further reduce the nation's financial expenditure on electricity problems. In the future case, BESS can even combine with clean energy and avoid their disadvantages to improve the situation of energy crisis and global warming.\newpage

\section{Related Work}
Comparing different methods and applying some novel algorithms that have not been applied to the BESS prediction problem are two of the motivations in this paper. Many algorithms have attempted to solve the BESS control problem or some problems which are related or similar to it. Exact algorithms can find the global optima of the problem instance, while heuristics may not guarantee the optimality but is more efficient.
\subsection{Exact Algorithm}
\subsubsection{Mixed Integer Linear Programming}
Eskil Sulen Gjerde \cite{milp} has implemented Mixed Integer Linear Programming (MILP) and Dynamic Programming (DP) for the BESS control problem. The paper compared them with some traditional methods on different measures: runtime and battery utilization. After collecting the results, the paper concluded that MILP ran an average of 5 times faster than DP and was easier to understand than DP. However, the paper only focused on two approaches without considering other algorithms and didn't use more metrics to measure different approaches. Hence, an in-depth comparison would make the conclusion more convincing in this paper.
\subsubsection{Dynamic Programming}
Muhammad Farooq \cite{dp} discussed DP and some pruning strategies. The time constraint was utilized to trim down the DP approach that was based on the Economy-7 tariff policy. This policy assumes that the tariff price would be kept low during some period in a day, hence, it is recommended that BESS charge and store energy during this period. In addition, there is another restriction called the Tariff Threshold Constraint that dictates that the BESS should discharge energy to power-consuming devices when the loads reach their peak limit, and import energy from the grid when the loads are at a low level. Furthermore, the BESS behavior is restricted by the load trend, which prohibits charging when the load is increasing and discharging when the load is decreasing. Another study conducted by Guillem Rigaill \cite{pdp2} concluded that pruning strategies would enhance the performance of the algorithm significantly by applying these strategies to DP on the K-change-points problem. However, in practice, the load trend constraint does not play a role in improving the quality of the solution. Therefore, the load trend constraint is dropped in pruned DP. However, Muhammad Farooq only focused on DP, though DP and pruning strategies have been studied in detail. In this paper, several approaches will be discussed and compared.
\subsection{Heuristic}
\subsubsection{Rolling Horizon Approach}
A heuristic that is suitable for time series problems like the BESS prediction control model has been studied by Glomb L.et al \cite{rolling}. The idea of the paper is to divide a long period into several small periods, and then solve the sub-problem within each range of the small periods-the result is called the initial solution and becomes the initial local optima. Then, the windows based on these ranges will move one step each time, and solve a new sub-problem within the window. The new solution with more information about the future will be compared with the local optima, the new solution will be accepted if the discrepancy between the solution and the local optimal is small. After moving the windows to the end, all the solutions of the sub-problems have been generated and they will form a completed solution for the entire problem. With the knowledge of the rolling idea, MILP and DP will be used to solve the sub-problem of the BESS control problem.
\subsubsection{Rule Based Heuristic}
 Another heuristic called the rule-based heuristic has been designed for some related problems by Michael Alexander Campbell \cite{rule}. At each time interval, the model will follow a series of rules and make a predefined operation. Furthermore, he created rules based on peak period and photovoltaic (PV) and customized high and low thresholds. However, since this paper doesn't consider the PV component, the rules, and their order has been changed, including the way to calculate two thresholds. Moreover, some prediction models of the loads will be applied to the rule-based heuristic which enables the heuristic to gather more information and make a more reasonable solution. \newline\newline
 Farias et.al \cite{anotherRule} proposed another different series of rules. Though that research concentrated on scheduling and real-time operation in electric vehicle charging stations. One kind of set of rules that have been discussed in their work is that according to the different amounts of remaining energy in the battery, the model will distribute different probabilities to different charge modes (with different charging rates). Hence, The idea will be covered in this paper while some finer control on the charging rate will be designed.
 
\subsection{Evaluation Method}
One of the motivations of this paper is to compare different methods in-depth, thus, the way to compare them is important. The article \cite{evaluation} has introduced 9 criteria for three performance category-efficiency, reliability, and quality of the solution. In this paper, only part of these most suitable criteria will be used to measure various methods.
\subsection{Extended}
Abronzini et.al \cite{degradation} collected the data from battery manufacturers to predict the achievable life cycles. After getting data on the depth of discharge at that time interval, with the predicted life cycles, the degradation cost can be calculated. Lee Jason \cite{linear} has verified that if the battery temperature is constant, then the rate of degradation is also constant. Moreover, he further provided the equation to calculate the degradation rate. Additionally, Zhou et.al \cite{lifecycle} figured out the relationship between the life cycle and depth of discharge for Lithium-Ion batteries. Hence, based on the depth of discharge, the life cycle is calculable. With the attempt to extend the model, the degradation component has been embedded in the rule-based heuristic in this paper.

\section{Description of the work}
\subsection{Problem}
The BESS prediction model problem is that given an electricity tariff structure and the electricity loads data, building a model that minimizes the total cost of electricity. The tariff structure varies from country to country, from time to time. However, in this project, all these values such as the peak and the electricity prices within the different periods are fixed. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{tariff.png}
    \caption{An example of tariff structure in a day~\cite{milp}}
\end{figure}
\noindent Figure 1 above shows a typical Time of Use tariff structure that contains most of the possible situations existing in a tariff. If the entire loads exceed the preset peak limit, then the price will rise for the excess. Otherwise, when the electrical load is maintained at normal levels, most of the time the price is also set at normal levels. Nonetheless, since the government or power companies attempt to prevent the excessive load from causing damage to the grid during peak times, the energy price will be set at a high level to encourage people to use electricity at other times. On the contrary, the demand decreases rapidly at some times like midnight, therefore, the price will be reduced to make full use of the power grid. Additionally, the structure in the figure also has a price for the export, which stands for the price when individual or business customers have some measures to generate energy or they want to sell the energy which is bought at a cheap price to make a profit. However, this project will not consider the export part, the introduction is only for completeness and objective.\newline\newline
When discussing the operations, continuous time is divided into time intervals of equal length because solving problem by searching the continuous solution space is infeasible for most of the time series algorithms. Hence, at a certain time interval, the model will do only one action. The model will try to find a sequence of operations, which can meet the needs of users and reduce the cost to the minimum. The ideal result is shown below. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{afterTheModel.png}
    \caption{The ideal result after applying the BESS model \cite{milp}}
\end{figure}

\noindent Under ideal circumstances the amount of charging controlled by the model when the price is cheap, can offset the loads exceeding peak limit or in peak period. Nevertheless, this ideal situation will not happen due to many constraints in real life. For instance, the efficiency of charge and discharge and the capacity of the battery will reduce as time goes by. In addition, the tariff structure is not always fixed in real life, which means the model has to receive the current price structure in real-time. The future loads data is unknown, which increases the prediction difficulty of the model. This project only focuses on the basic problem, hence, the optimization approaches will try to find the best solution under some of these constraints.

\subsection{Model}
Each time interval has a load $L_{i}\in \mathbb{R} $ which stands for the consumption at that time. The battery in BESS has a maximum capacity of $B_{max}$, maximum input and output power of $Po$, the amount of charge or discharge of $p_{i}$ at each time interval where $-Po\leq p_{i} \leq Po$. In the electricity tariff structure, $P_{ij}$ stands for the price at certain time intervals and load levels. For $j=0$ and $j=1$, they stand for the situation when loads are at normal level and peak level $PL$. The price for time $i$ is calculated by
\begin{equation}
    P_{i}=
    \begin{cases}
        (L_i+p_{i}-PL)*P_{i1}+PL*P_{i0}, & \mbox{if } L_i+p_i>PL\\
        (L_i+p_{i})*P_{i0},             & \mbox{if } 0\leq L_i+p_i\leq PL
        
    \end{cases}
\end{equation}
\noindent Hence, the cost function is
\begin{equation}
    P=\sum_{i=0}^{T-1}P_i, \mbox{T is time interval}
\end{equation}

\subsection{Objective and Aim}
The project aims to compare different methods in depth, including success rate, percentage of global optimal found, runtime, and memory usage comparison. Such comparisons can rarely be found in other papers. Except for comparisons, this paper similarly focuses on novelty. some methods that have not been applied to the BESS prediction control model are also implemented in the project, to find out if there is a better method. 

\section{Methodology}
\subsection{MILP}
MILP is a mathematical optimization algorithm with some linear constraints and one linear objective function. Apart from linear programming, MILP also allows the mixing of discrete decision variables which means limiting variables to integers and continuous decision variables together. The model built by MILP applies a combination of some linear programming techniques and branch-and-bound methods, which enables the model to search the solution space to find the optima more efficiently. The branch-and-bound approach will break down a problem into smaller sub-problems and systematically explore the solution space of each sub-problem. Additionally, linear programming techniques are employed to establish bounds on the objective function. At first, MILP will apply linear programming to find the optimal solution. Nonetheless, if one or more integer decision variables that are necessary for the optimal solution take non-integer values, choose one of the variables, and separate the problem into two sub-problems according to the integer variable. Each of the sub-problems will generate a new constraint based on the integer closest to that variable. The figure below shows how the Branch and Bound method works in the MILP. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{BranchBound.png}
    \caption{An example of Branch and Bound method}
\end{figure}
\noindent After dividing the problem into two sub-problems, MILP will again use linear programming to solve these sub-problems. If there are still integer variables whose values are not integers, repeat the division behavior of the branch and bound until all of the integer decision variables that reach the optimal solution have integer values. Moreover, the optimal solution of these sub-problems is selected as the optimal solution of the whole problem. While traversing the solution space, due to the properties of the branch and bound method, many subsets of solution space that don't need to be evaluated can be discarded since the integer decision variables don't satisfy the integer property. Hence, by a combination of linear programming and the branch and bound method, the MILP's computational efficiency is greatly improved and the optimality of the solution is still guaranteed. \newline\newline
\noindent MILP is an exact approach which means it can find optimal solutions to complex optimization problems with discrete decisions. Moreover, according to Gjerde Eskil Sulen \cite{milp}, the MILP runs faster than some algorithms like DP. Though understanding how MILP exactly work is difficult, it is easy to implement it with the help of some IDE or framework. The MILP will generate many constraints according to the limitations of various conditions in reality. For instance, the energy inside the battery is always greater than 0 and less than the capacity of the battery for the different states of the battery located at all the time intervals. Additionally, due to the tariff structure, the energy needed to be imported from the grid is segmented into several sections and each of which has a different price. Hence, the MILP has to generate additional constraints to ensure the equality between import energy and the sum of different energy sections. 
\subsection{Dynamic Programming}
DP is a traditional algorithm to solve optimization problems. It can break the original problem into several sub-problems because the solution of the sub-problem can contribute to the final solution of the original problem. Additionally, the solution to the sub-problem will be stored since they will be reused in some way. DP has two different types of implementation-top down and bottom up. For top down DP, the problem is firstly broken into several sub-problems and then the algorithm computes sub-problems recursively with the result stored in a table. For bottom up DP, the sub-problem is solved iteratively and finally composes the final solution of the large problem. The bottom up method is adopted in this project because it is more suitable for the BESS control problem with a sequential structure.\newpage\noindent
The most significant reason for applying DP is the feature that DP can help find optimal solutions. Hence, by combing the result of MILP and DP, verifying whether a global solution has been found is simple. Furthermore, DP is easy to understand and implement. All of the computational steps are iterative or recursive which can learn the structure of the problem by learning from the simple sub-problem. At each time interval, different states have been divided according to the amount of energy inside the battery to enable the searching in solution space. Hence, the sub-problem is defined as the minimum cost calculated from the start time interval with no energy in the battery to the current time interval with fixed battery energy. After solving all the sub-problems, the answer to the original problem is solved because based on the solution of minimum cost from the start time interval to the previous time interval, it is easy to get a solution from the previous time interval to the current time interval. 
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{dp.png}
    \caption{An example of a model built by Dynamic Programming}
\end{figure}
\noindent Figure 4 shows the structure of the DP and the nodes are the states of the battery (remaining energy in the battery) in different time intervals. The blue nodes stand for reachable states and the black nodes stand for unreachable nodes. The reachable node is defined as when starting from the beginning node, after making some operations of charge and discharge, the node which can be reached. Moving from one state at a time interval to the state at the next interval represents the charge and discharge behavior-moving to a higher state means importing energy from the grid and charging the battery, inversely, moving to a lower state is discharge from the battery and using the energy for the loads. The difference between nodes and their neighbor is shown as $\Delta energy$, which is the minimum change of energy of different states between nearby time intervals. On the contrary, the nodes' maximum change of energy is constrained by the maximum input and output power of energy, which is set to equal in this project. Not only the node (or state) contains information of the state of charge of the battery but also contains the energy cost from the beginning state to the current state.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{DPSolving.jpg}
    \caption{How DP works to solve the BESS control problem}
\end{figure}
\noindent Figure 5 shows the reason why DP can find the optimal of the sub-problem. Due to the varying electricity price in the tariff structure, the same energy may have different prices. This feature is the key idea of DP. As shown in the figure above, there are different paths to reach that node by the act of charging and discharging a battery. After calculating the total cost given the current electricity price, battery charging and discharging status, and load information, the cost at the current time interval and current state can be calculated. Hence, by comparing different costs and choosing the minimum one, the sub-problem at its current status can be solved.

\subsubsection{Pruning Strategies}
According to the work of Muhammad Farooq \cite{dp}, several pruning strategies have been applied to improve the efficiency of DP.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{timeConstraint.png}
    \caption{Time Constraint}
\end{figure}
\noindent Figure 6 shows how the time constraint pruning strategy applies to DP. When the price is at a normal level, no pruning is applied. However, since the government or electric power companies will adjust the price to perform peak shaving, the price will become very cheap or expensive for a certain period of time. Hence, to buy energy at a cheap price to avoid electricity consumption at a high price, under no circumstance should DP perform discharge when the price is cheap, similarly discharge when the price is high. Another constraint called tariff threshold constraint works in a way similar to time constraint. When the load exceeds the peak limit, charging behavior is disabled because the price is high under such circumstances. The behavior is exactly the opposite when the load doesn't exceed.

\subsection{Rolling Horizon Approach}
Due to the fact that the BESS control problem requires making complex decisions over a large time-span search space and the data in the problem repeats in a similar identical way, the rolling horizon approach can take advantage of such properties. The method will focus on solving the subsequence of the problem. An example of the structure of the rolling horizon can be found in Figure 7.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{rolling.png}
    \caption{Rolling Horizon Approach}
\end{figure}
\noindent The approach will create a fixed-size window within a sub-problem. Then another problem-specific algorithm will be applied to this sub-problem and get an optimal solution with a sequence of operations for this sub-problem. As a result, the operations and the cost at each time interval are stored. After that, move the window forward by 1 time interval, solve the new sub-problem, and overwrite the operations and cost for each time interval within the window. The distance the window moved can be set, nevertheless, to improve the optimality of the final solution, it is moved only one time interval at each step. By iteratively moving the window and solving the problem, all the operations will be found and fixed. As a consequence, the complete sequence of operations is then solved.\newline\newline
Rolling horizon has been applied to a large number of different problems and for some of those problems, the rolling approach's efficiency has been proved \cite{rolling}. The efficient calculation is vital in this BESS control problem due to its large scale. Moreover, the rolling horizon approach is able to find a solution that is close to to the global optimal solution. Another key factor for applying the rolling horizon approach is that the algorithm doesn't need global knowledge which makes the model more realistic. In reality, it's impractical to know the future information about the tariff structure and the loads in-home or in companies, thus only partial information is known which is suitable for the rolling approach. Last but not least, unlike MILP and DP, the rolling horizon approach is designed for such time series problems like the BESS control problem and it has not been applied to this problem in previous work, hence, this will add novelty to the project.\newline\newline
However, the rolling approach is an algorithm that can be widely used in different problems and different fields, therefore the problem-specific algorithm is required to solve the sub-problem generated by the rolling approach. Hence, that's where MILP and DP come in. Within each window, apply MILP or DP to find the sequences of operations that minimize the cost of the sub-problem. 
\subsubsection{Improved Rolling Horizon Approach}
However, though the rolling horizon method guarantees near-optimal in the current period, this information will never be used in future periods when making optimal decisions. As a result, the simple rolling method is not able to guarantee any quality. Hence, an improved rolling horizon approach is designed by L. Glomb et.al \cite{rolling}. On the basis of the rolling horizon approach, it generates a new constraint to guarantee the quality of the solution. The improved approach divides the entire problem into several fixed, consecutive sub-problems according to the window size.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{rollingdivision.png}
    \caption{The fixed sub-problem divided by the approach}
\end{figure}
\noindent
The window is the range of the sub-problem need to be solved using problem-specific algorithms. The window starts from the beginning time interval of the original problem and moves 1 step at each iteration. At first, when the window overlaps the sub-problem, use the simple rolling horizon to get the optimal solution of the fixed sub-problem and store it. It needs to be explained that the word "overlap" means that the start time interval and the end time interval of the sub-problem within the window and the fixed sub-problem are the same. The figure below shows an example of overlapping and use dotted box to represent the window:
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{improvedoverlapper.png}
    \caption{The example of overlapping}
\end{figure}
\noindent After that, the window will keep moving and make new solutions consisting of a series of operations with more future information. The operation stands for the decisions made at each time interval and different operations (charge or discharge and the amount of the energy) will lead to various result solution. As long as the window intersects with the fixed sub-problem, the influence of new operations on the optimality of the solution of the fixed sub-problem will be considered.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{uselessintersect.png}
    \caption{The example of the useless intersection}
\end{figure}
\noindent
 It should be explained that only after the window has overlapped the fixed sub-problem can the new operations (new solution) have an impact on the solution of the fixed sub-problem. Because though the window intersects a fixed sub-problem before overlapping it and the operations are stored at intersected time intervals, when the window moves and overlaps with that fixed sub-problem, all the operations makes up the optimal solution of the fixed sub-problem will be stored and overwrite all the previous information. Consequently, the operations stored before overlapping will have no influence on that the final solution of the fixed sub-problem. Therefore, the intersection only refers to the intersection after overlaps happen. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{improvedworks.png}
    \caption{The example of intersection and how it influences on solution}
\end{figure}
\noindent Currently, there are two sets of solutions for the intersected area: the previous stored solution and the new solution generated within the window. Moreover, each operation of the previous and current solution at the same time interval is different, which makes the solution of the fixed sub-problem also different. Hence, the improved rolling horizon approach will compare the value of the previous solution with the value of the new solution with replaced operations in the intersected area. Since the solution in the current window with more future information is more likely to improve the quality of the final solution, if the new solution based on more future information is only slightly worse than optimal, accept and overwrite the existing operations, otherwise discard the new sequence of operations and keep the solution with previous operations. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{improvedrolling.png}
    \caption{Improved Rolling Horizon Approach}
\end{figure}

\noindent
Figure 12 shows a more comprehensive workflow of the improved rolling horizon approach. The black frame stands for the fixed sub-problem whose solution is known and all the windows at each step drawn in the example above intersect with the black frame (fixed sub-problem). One operation is fixed at each step based on some future information. 

\subsection{Rule-based Heuristic}
Rule-based heuristics always take the current load and price as input and then follow a series of rules. After the traversal of the entire rule chain, the only result operation will be picked and performed.\newline\newline
Compared to other algorithms, it is simple to implement the rule-based heuristic for the BESS control problem since only several rules need to be set. Moreover, unlike all the previous approaches, the whole approach has no complex structure and doesn't need an additional data structure to store other information. Hence, the amount of memory required is very small. For the same reason, running a rule-based heuristic takes only a short period of time to get the result. Additionally, since the rule-based heuristic doesn't require any future information and only depends on the information at the current time interval, it is more consistent with the lack of information in the real world. Hence, with the fast running speed and current information, the approach can react quickly to the change in price or load which makes the rule-based heuristic a real-time method. Meanwhile, on account of such property, the optimality of the solution will not be guaranteed with no future information. Consequently, as opposed to MILP being able to find the global optimal, rule-based heuristic puts a lower bound on the minimum cost \cite{rule}.\newline\newline
As shown in Figure 13, there are four main rules for different situations: the load exceeds the peak limit, the price is high, normal, or cheap. When the load surpasses the peak limit or the price is at a high level, only discharge behavior is allowed. However, when the price is at a high level, the amount of discharge depends on the ratio of remaining energy in the battery to the battery capacity. Inversely, when the price is at a normal level or cheap level, the algorithm will perform a discharge operation. Since it is more profitable to charge the battery at a cheap level, the approach will only charge limitedly at a normal price and charge as much as the battery can when the price is cheap. The amount of energy to charge is calculated based on the ratio of the current load to the peak limit. If the load is closer to the peak limit, the loads in the future are more likely to be greater than the peak limit. Hence, the battery should charge as much possible as and that's the reason to use the ratio. Additionally, the remaining energy in the battery and the maximum output power of the battery must be considered when discharging, because under no circumstance should a battery discharge efficiency be greater than the maximum output power or discharge the amount of the energy be greater than the remaining energy. Similarly, when charging the battery, the amount of energy at the current time should not be greater than the maximum input power and capacity of the battery. Furthermore, if the sum of the current load and the energy needed to be imported into the battery exceeds the peak limit, then the excess portion will be charged a high fee which will increase unnecessary expenses. Hence, this secondary rule should be added to the discharging rule chain to improve the quality of the solution.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{myflowchart.jpg}
    \caption{Simple rule-based heuristic}
\end{figure}
\noindent 

\subsubsection{Rule-based Heuristic with Prediction}
The rule-based heuristic only makes predictions based on current information, which may lower the quality of the solution. Furthermore, this problem is based on data that is cyclical: the load data this week or today may be similar to the previous week or yesterday. Hence, with previous information, a load prediction model can be built to forecast the future load which can help to control the current operation based on this information. This paper only focuses on the previous day's load information.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{RulewithPrediction.png}
    \caption{The rule chains of rule-based heuristic with prediction component}
\end{figure}
\noindent The load prediction model predicts the best operation based on yesterday's data and then the rule-based heuristic follows the result generated by that model. As shown in Figure 14, if the prediction model doesn't have any previous information, the current load is greater than the peak limit, or the current price is at a normal or cheap level, run the previous simple rule-based heuristic. Otherwise, if the price is at a high level and the load doesn't surpass the peak limit, then the load at the current time will be compared with the load yesterday at the same time position. Assuming the difference between the two loads is not significant, the trend of the loads at the same time yesterday may repeat at the current time. Hence, previous information can be used to measure what operation should be performed now. Provided that most of the previous loads have exceeded the peak limit, it is likely that future loads will mostly exceed the peak limit. Hence, given the price when the peak limit is surpassed is more expensive than the price at a high level, it isn't cost-effective if the battery discharges at the current time interval. Therefore, the model will tell the rule-based heuristic not to perform any charge or discharge operations. Moreover, if only some of the loads of yesterday exceed the peak limit, to make full use of the energy in the battery, do limited discharge which is calculated in a similar way to the limited charge introduced above. Furthermore, if none of the previous loads were greater than the peak limit, then discharge as much as the battery can.\newline\newline
Another case is that the current load is different from yesterday's load at the same time, which implies that the previous information has lost its meaning and becomes useless. Hence, prediction is made only depending on the current load information. Providing that the current load is far away from the peak limit, then it is possible that there are fewer loads which is greater than the peak limit in the future. Hence, it is unnecessary to save energy in the battery and then the battery can perform the discharging operation without artificial limitation. Otherwise, assuming the load is approaching the peak limit, thus it is more likely that many loads will surpass the peak limit in the future. Hence, for the last case, if the load is neither close to the peak limit nor far away from it, then only limited discharge is carried out.

\section{Implementation}
In this project, most of the hyperparameters-battery capacity, maximum input and output power, and tariff structure-are fixed to simplify the comparison between different models. Only one hyperparameter, the window size, in the improved rolling horizon will be tuned and tested.  
\subsection{MILP}
The MILP model was first implemented in IBM ILOG CPLEX Studio using Optimization Problem Language (OPL), which provides a rich set of tools for model development. However, to avoid the negative impact on the result caused by different platform and language, the MILP is implemented in Java with a external Cplex jar library. The MILP method requires an objective function consisting of decision variables to minimize or maximize. Additionally, the value of decision variables shouldn't break any constraints and no slack is allowed. The symbols of the MILP method are shown below.
\begin{table}[H]
\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}|  }
 \hline
 Symbol &\multicolumn{3}{|c|}{Description} \\
 \hline
 $e_{ij}$ & \multicolumn{3}{|l|}{the energy at time interval $i$ for price level $j$}\\
 $P_{ij}$   & \multicolumn{3}{|l|}{the price at time interval $i$ for price level $j$}\\
 $Po$&   \multicolumn{3}{|l|}{the maximum input and output power of the battery}\\
 $p_i$ &\multicolumn{3}{|l|}{the amount of energy that battery charges or discharges at time interval $i$}\\
 $L_i$    &\multicolumn{3}{|l|}{the load at time interval $i$}\\
 $B_{start}$&\multicolumn{3}{|l|}{the energy in the battery at the beginning}\\
 $B_{max}$&\multicolumn{3}{|l|}{the capacity of the battery}\\
 $b_{i}$&\multicolumn{3}{|l|}{the energy remained in the battery at time interval $i$}\\
 $PL$& \multicolumn{3}{|l|}{the peak limit in the tariff structure}\\
 $N_1$& \multicolumn{3}{|l|}{the number of time intervals}\\
 $N_2$& \multicolumn{3}{|l|}{the number of different price levels}\\
 $C$& \multicolumn{3}{|l|}{the total cost of the problem}\\
 \hline
\end{tabular}
\caption{\label{demo-table}The symbols appear in the model}
\end{table}\noindent
The decision variable $e_{ij}$ stands for the energy at time interval $i$ and price level $j$. The price is split into two levels-one price level for energy usage below the peak limit, and another for over the peak limit. The MILP model is defined as below which has one objective function to minimize and several constraints \newline
\begin{equation}
%\begin{array}{ll@{}p{3cm}p{3cm}}
\begin{array}{llll}
\text{Minimize} \quad & C=\displaystyle\sum\limits_{i=1}^{N_1}\displaystyle\sum\limits_{j=1}^{N_2} e_{ij}*P_{ij}&&i=1,...,N_1 \quad j=1,...,N_2\\ \\
\text{subject to} \quad & -Po \leq b_i-b_{i-1} \leq Po & & i=1,...,N_1\\ \\
 & 0\leq b_i \leq B_{max} & &i = 1,...,N_1\\ \\
 & B_0 = B_{start} && \\ \\
  &e_{i1}+e_{i2}=L_i+(b_i-b_{i-1}) && i = 1,...,N_1 \\ \\
  &e_{i1}\leq PL & & i=1,...,N_1 \\ \\
  & 0 \leq e_{ij} & & i=1,...,N_1 \quad j=1,...,N_2
\end{array}
\end{equation}

\noindent The objective function calculates the sum of the cost at all the time intervals and the cost at each time interval is the sum of the multiplication of the energy $e_{ij}$ at each price level $j$ and its corresponding price $P_{ij}$. \newline\newline
The first constraint means that the difference between the remaining energy in the battery at the current time interval and the previous time interval, which is the amount of charge or discharge ($b_i-b_{i-1}$), shouldn't exceed the maximum input and output power of the battery. $-Po$ stands for the maximum output energy of the battery at each time interval, inversely, $Po$ is the maximum input energy. \newline\newline
The second constraint restricts the status of the battery at all time intervals. Although it is natural that the energy in the battery can never be negative and never exceed the capacity of the battery, it is still necessary to add this constraint to the model. The next constraint set the battery at the beginning empty which is in line with reality when the model is first applied to the BESS control problem.\newline\newline
The remaining three constraints are all for energy in each time interval. The first in these constraints calculates the sum of the load at the current time interval $i$ and the amount of charge or discharge, which represents the total energy imported from the grid at that time interval. Moreover, the energy will be split into two parts based on the next constraint. Since the energy $e_{i1}$ is the energy at the first price level, by the definition $e_{i1}$ should never exceed the peak limit. The last constraint means different parts of the energy at all time intervals $e_{ij}$ should always be greater than zero and in this project, the export component is not considered. 
\subsection{Dynamic Programming}
Since Java language is popular-with many useful library-and robust, DP is implemented using Java. This project imports a opencsv package with this capability from a third party can read csv files quickly and efficiently. \newline\newline
DP will divide the battery into different states and each state stores the information about whether the state is available, the remaining energy in the battery $b_i$, and the total cost incurred when all the loads and the sequence of operations performed from the start to the present time interval $i$ reach this state.
\begin{table}[H]
\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}|  }
 \hline
 Symbol &\multicolumn{3}{|c|}{Description} \\
 \hline
 $N_3$ & \multicolumn{3}{|l|}{the number of the states at each time interval}\\
 $ND_{ij}$   & \multicolumn{3}{|l|}{the state at time interval $i$ and state position $j$}\\
 $D$&   \multicolumn{3}{|l|}{the difference between two neighbourhood state}\\
 $N_4$ &\multicolumn{3}{|l|}{the maximum number of the states in one direction can}\\
&\multicolumn{3}{|l|}{be reached current state}\\
 
 \hline
\end{tabular}
\caption{\label{demo-table1}The additional symbols appear in the DP}
\end{table}\noindent
The user sets the number of states $N_3$ and the difference $D$ between two neighboring states can be calculated by dividing the battery capacity $B_{max}$ by the number of states $N_3$. After calculating the difference $D$, the maximum number of the states $N_4$ is calculated by rounding off the decimal part of the result of dividing the maximum input and output power $Po$ by the difference $D$.
\newline
\begin{breakablealgorithm}[H]
        \caption{Dynamic Programming's Core Function}
        \begin{algorithmic}[1]
            % \Procedure CAREFUL FINITE FORESIGHT OPTIMIZATION $(P_{\textbf{T}},\mu,\varepsilon)$
            \For{$i = 0 \xrightarrow{} N_1-1$}
                \For{$j = 0 \xrightarrow{} N_3-1$}
                    \If {$ND_{i,j} \text{ is not Available}$}
                        \State \text{Skip to next iteration}
                    \EndIf
                    \For {$action \in ActionSpace$}
                        \If {$action == \text{NoAction} $}
                            \State {$price = \text{caculatePrice}(i,0)$}
                            \If{$ND_{i,j}.cost+price<ND_{i+1,j}.cost$}
                                \State{$ND_{i+1,j}.cost \xleftarrow{} ND_{i,j}.cost+price$}
                                \State {$ND_{i+1,j} \text{ is now Available}$}
                            \EndIf
                        \EndIf
                        \If {$action == \text{Charge} $}
                            \For{$k = 1 \xrightarrow{} N_4 $}
                                \If{$j+k>N_4-1$}
                                    \State \text{Skip to next iteration}
                                \EndIf
                                \State {$price = \text{caculatePrice}(i,k*D)$}
                                \If{$ND_{i,j}.cost+price<ND_{i+1,j+k}.cost$}
                                    \State{$ND_{i+1,j+k}.cost \xleftarrow{} ND_{i,j}.cost+price$}
                                    \State {$ND_{i+1,j+k} \text{ is now Available}$}
                                \EndIf
                            \EndFor
                        \EndIf
                        \If {$action == \text{Discharge} $}
                            \For{$k = 1 \xrightarrow{} N_4 $}
                                \If{$j-k<0$}
                                    \State \text{Skip to next iteration}
                                \EndIf
                                \State {$price = \text{caculatePrice}(i,-k*D)$}
                                \If{$ND_{i,j}.cost+price<ND_{i+1,j-k}.cost$}
                                    \State{$ND_{i+1,j-k}.cost \xleftarrow{} ND_{i,j}.cost+price$}
                                    \State {$ND_{i+1,j-k} \text{ is now Available}$}
                                \EndIf
                            \EndFor
                        \EndIf
                        
                    \EndFor
                \EndFor
            \EndFor
            
            % \EndProcedure
        \end{algorithmic} 
    \end{breakablealgorithm}
\noindent
The pseudocode above shows the core function of DP. The state $j$ at each time interval $i$ stands for a sub-problem $ND_{i,j}$-look for the minimum cost at the current time interval with fixed remaining energy in the battery at the current state. Since this paper uses bottom up DP, the model will traverse the sub-problems in all states from the beginning time interval to the final time interval and each sub-problem's solution contributes to the next optimal solution of the sub-problem in the next time interval. As long as the state at that time interval is available, which means the sub-problem at that state has the optimal solution and can form a global optimal to the sub-problems at the next time interval. Hence, three actions can be taken by the model-charge, discharge, and no operation. The maximum number of the states $N_4$ in one direction has been calculated, which stands for the different amounts of energy that can be charged or discharged from the battery. At each state traverse all the possible actions and calculate the cost of the solution, compare it with the current solution's cost stored in the target state, choose the best one, and store it for the next calculation.
\subsubsection{Pruning Strategies}
The pruning strategies can be applied to DP to improve the efficiency of the model. At the beginning of traversing the states at each time interval, a flag is used to describe the status at the current time. When the price is cheap at the time interval, under no circumstance should any discharge operation be performed because it's not cost-effective. Therefore, the flag will be set to inform the model not to consider the related calculation. On the contrary, if the price is expensive at that time or the load has exceeded the peak limit which drives up the cost (two constraints have been combined when setting the value of the flag), don't consider any charge behavior which greatly increases the cost. For the same reason, the flag will tell the model not to do the calculations.


\subsection{Rolling Horizon Approach}
Due to differences in performance between platforms and languages, in order to avoid the impact of using too many different platforms and languages on the difference in calculation results, the rolling horizon approach is implemented using the Java language like DP.
\begin{table}[H]
\begin{tabular}{ |p{4cm}||p{2cm}|p{2cm}|p{2cm}|  }
 \hline
 Symbol &\multicolumn{3}{|c|}{Description} \\
 \hline
 $\mu$ \textbf{or} $windowSize$ & \multicolumn{3}{|l|}{the size of the window ( or fixed sub-problem)}\\
 $\varepsilon$ \textbf{or} $rateOfDeviation$  & \multicolumn{3}{|l|}{The portion of relaxation which is allowed for the new solution}\\
 $Problem_{index,len}$  & \multicolumn{3}{|l|}{the problem starts from $index$ time interval and the size}\\
 & \multicolumn{3}{|l|}{of the problem is $len$}\\
 $solution_{index,len}$  & \multicolumn{3}{|l|}{the new solution of the problem with future information, starts from}\\
& \multicolumn{3}{|l|}{$index$ time interval and the size of the problem is $len$}\\
 $optimal_{index,len}$ & \multicolumn{3}{|l|}{the optimal solution of the problem starts from $index$ }\\
 & \multicolumn{3}{|l|}{time interval and the size of the problem is $len$}\\
 
 \hline
\end{tabular}
\caption{\label{demo-table1}The additional symbols appear in the improved rolling approach}
\end{table}\noindent
$\mu$ is a hyperparameter that will be tuned in the project because the size of the window and sub-problem has an impact on the quality of the solution. $\varepsilon$ is another hyperparameter but it is fixed due to the lack of time to tune and compare different values' influence. In the pseudocode below, use the $windowSize$ represents $\mu$, the $rateOfDeviation$ represents $\varepsilon$.\newline
\begin{breakablealgorithm}
    \caption{Improved Rolling Horizon approaches \cite{rolling}}
    \begin{algorithmic}[1]
        \Require {A sequence of minimization problem $Problem,windowSize < N_1, rateOfDeviation>0 $}
        \Ensure {A solution $(energy_t)_{t\in N_1-1}$ of $Problem$}
        \Procedure {Improved Rolling Horizon}{$Problem,windowSize,rateOfDeviation$}
        \State $smallWindowSize \gets N_1-\lfloor N_1-1 \rfloor_{windowSize}$
            
        \State $(energy_t)_{0\leq t<windowSize} \gets $ \text{argmin} $ Problem_{0,windowSize-1}$
        \State \text{s.t. }$solution_{0,smallWindowSize-1}\leq (1+rateOfDeviation)optimal_{0,smallWindowSize-1}$
        \For{$t \in \{1,...,smallWindowSize\}$}
            \State {$(energy_j)_{t\leq j <t+windowSize} \gets$ argmin $Problem_{t,windowSize-1}$}
            \State {s.t. $solution_{0,smallWindowSize-1}^{new}\leq (1+rateOfDeviation)optimal_{0,smallWindowSize-1}$}
        \EndFor
            
        \For{$t\in $\{0,...,$\lfloor \frac{N_1-1}{windowSize} \rfloor-2$\}}
            \For{$j\in \{smallWindowSize+1,...,windowSize+smallWindowSize\}$}
                \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{$(energy_j)_{windowSize\cdot t +j\leq l < windowSize\cdot(t+1)+j} \xleftarrow{}$\newline \text{argmin} $Problem_{windowSize (t+1),windowSize-1}$}
                \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\text{s.t. }$solution_{windowSize\cdot t+smallWindowSize,windowSize-1}^{new} \leq $\newline
                $(1+rateOfDeviation)\cdot optimal_{windowSize\cdot t+smallWindowSize,windowSize-1}$}
            \EndFor
        \EndFor
        \State \Return {$(energy_t)_{t\in N_1-1}$}
        \EndProcedure
    \end{algorithmic} 
\end{breakablealgorithm}

\noindent
The algorithm shown above represents the improved rolling horizon approach. $\lfloor \textbf{$N_1$-1} \rfloor_{windowSize}$ represents the maximum size of the number of the fixed problems generated by the model according to the window size. Hence, $smallWindowSize$ is the number of remaining time intervals which is not enough to satisfy the window size $windowSize$ but has to be considered. The algorithm will first determine the sequence of energy $energy_t$ in the solution of the sub-problem within window size $windowSize$ using some future information that contains the operations of the fixed sub-problem $Problem_{0,smallWindowSize-1}$. Afterward, start a loop to traverse all the time intervals in the previous fixed sub-problem to compare the existing solution and solution with a combination of previous information and future information at each time interval. After the loop, all the operations in the previous fixed sub-problem have been determined. Hence, the remaining elements divided into fixed sub-problems with the same size of the window size $windowSize$ can use a nested loop to determine and change the operations in the solution of each fixed sub-problem. The reason for the nested loop is the same as the previous one.

\subsubsection{Dynamic Programming}
When implementing the rolling horizon approach, a problem-specific algorithm needs to be determined to solve the sub-problem within the window. At first, DP is taken as that algorithm in the model, but the overall runtime of the model is lengthy. Although the paper \cite{rolling} describes the rolling method as an efficient algorithm, in practice, DP actually makes the runtime longer. \newline
The runtime of the DP: 
\begin{equation}
    f(n) = O(N_1N_3N_4)
\end{equation}
When calculating the complexity, the details of the price calculation, comparison, and judgment are treated as $O(1)$. The total number of states the model will traverse is $O(N_1N_3)$ and the number of the states $N_4$ in one direction which can be reached by each state (the actual number of the states can be reached by one state is 2$N_3$+1, and the factors and constant can be ignored). Hence, the time complexity is $O(N_1N_3N_4)$ \newline
\noindent
The runtime of the rolling horizon approach based on DP:
\begin{equation}
    f(n) = O(\mu N_1N_3N_4)
\end{equation}
$N_1$ represents the number of sub-problems to be solved. Since at each time the window only forward by 1 step, hence the number of sub-problems only differs from the number of time intervals by a small constant which can be ignored in time complexity. It is important that the number of fixed sub-problems is ignored since it is just a constant. $\mu$ represents the number of time intervals of the sub-problem, $N_3$ stands for the number of states in the sub-problems and $N_4$ stands for the number of the states which can be reached by each state. Hence, the total complexity can be calculated by multiplying the number of sub-problems $N_1$ and the time complexity of the sub-problems $O(\mu N_3N_4)$. \newline\newline
Consequently, comparing DP and the rolling horizon approach based on DP, it is clear that applying the rolling horizon approach to DP can't improve efficiency. 
\subsubsection{MILP}
Since the improved rolling horizon approach based on DP lost its efficiency of what it should be, this project changed into another problem-specific algorithm MILP to increase the speed of running. Additionally, when implementing this rolling approach, a CPLEX jar package from IBM is imported into the project to assist the model. The worst time complexity of the MILP is usually exponential. However, the actual time complexity highly depends on other factors-the problem structure and the solver algorithm.
\noindent The details of the rolling horizon approach implementation has slightly changed, but the idea of the rolling horizon approach has not. Specifically, the way to determine the number of fixed sub-problems to be iterated has been changed:\newline
\begin{equation}
    I=
    \begin{cases}
        \frac{N_1}{\mu} -2, & \text{if } N_1 \% \mu = 0\\
        \frac{N_1}{\mu} -1, & Otherwise
    \end{cases}
\end{equation} \newline
$I$ represents the number of fixed sub-problems to be iterated. If $N_1 \% \mu$ is equal to zero, which means the entire problem is divisible by the window size. Hence, apart from the last fixed sub-problem with no future information to improve the quality of the solution, all previous fixed sub-problems should be traversed using future information that decide $I$. Otherwise, a small size fixed sub-problem will be generated and is iterated in a different way. Therefore, the number of fixed sub-problems to be traversed should decrease by 1.\newline\newline
However, after implementing the improved rolling horizon approach based on MILP, the algorithm . During initial testing, compared to the basic rolling horizon approach based on MILP, it makes the model harder to understand and increases runtime and memory usage. Moreover, the basic rolling horizon approach can generated solutions that are as close to the global optimal as the improved approach. Therefore, only basic approach will be used to compared with other algorithms. 
\subsection{Rule-based Heuristic}
The total cost is calculated by summing up the cost by following the rules at each time interval. The load and current tariff structure will be considered in the rules and the model will attempt to generate a reasonable decision at each time interval. When the load doesn't exceed the peak limit and the price level is normal, the amount of energy a battery can charge when other constraints are not considered is calculated:
\begin{equation}
    RE_i = Po \frac{L_i}{PL}
\end{equation}\newline
$RE_i$ stands for the maximum amount of energy the battery can charge at that time interval. If the load at time interval $i$ is approaching the peak limit, it is more likely that the load will rise in the future and exceed the peak limit. Hence, the battery should charge as much as it can when the price is at a normal level and discharge for the excessive in the future to reduce the cost. Consequently, $\frac{L_i}{PL}$ is used to adjust the amount of energy to charge. Apparently, the load $L_i$ plus the energy to charge should not surpass the peak limit $PL$ and the amount of charge should not exceed the battery capacity $B_{max}$.\newline\newline
When the load exceeds the peak limit, discharge for the excessive part. The rules are expressed below: 
\begin{equation}
    DE_i = -\min(L_i-PL,Po,b_i)
\end{equation}
First, the amount of energy to discharge $DE_i$ shouldn't be greater than the maximum output power and the remaining energy in the battery. Afterward, discharge as much as the portion of the load that exceeds the peak limit.\newline\newline
When the price is at a high level, the maximum amount of energy allowed to discharge is:
\begin{equation}
    RE_i = -Po \frac{b_i}{B_{max}}
\end{equation}\newline
If the remaining energy in the battery is little, it is more cost-effective to keep the energy and discharge when the load exceeds the peak limit since the price for the peak limit is higher. Consequently, $\frac{b_i}{B_{max}}$ is used to adjust the amount of energy to discharge. Additionally, this energy should also be compared with the remaining energy in the battery and the load. \newline\newline
When the price is cheap, the amount of energy to charge is:
\begin{equation}
    CE_i = min(PL-L_i,Po,B_{max}-b_{i})
\end{equation}\newline
The amount of energy to charge should be as much as possible when the price is cheap. However, there are some constraints to obey. Initially, $PL-L_i$ means that the energy of charge plus the load at the current time interval $L_i$ should not exceed the peak limit which will increase the cost. Moreover, $B_{max}-b_i$ represents that the sum of the amount of the charge and the remaining energy in the battery should not exceed the battery capacity. \newline\newline
Though the rule-based heuristic is more efficient and uses less memory, the quality of the solution needs to be improved. Hence, a prediction model is introduced in the heuristic.

\subsubsection{Rule-based Heuristic with Prediction}
In the prediction component, in addition to the information on the current load, the previous loads' information from the same position yesterday is used to predict the trend of the future loads and improve the quality of the solution. The prediction model is composed of many conditional expressions, and each of the expressions will return a flag that can instruct the model to proceed to the next step. \newline\newline
At first, the prediction model will examine whether there is any previously available information that can be utilized. If such information doesn't exist, then return a flag to inform the heuristic to run a simple rule-based heuristic using only current load information to make an operation. On the contrary, if the prediction model finds out that the current load has surpassed the peak limit or the price is at a normal or cheap level, the prediction model will return a flag to instruct the heuristic to perform as the simple rule-based heuristic. \newline\newline
For a special case when the price is set to a high level, a dilemma arises: if the loads in the future will exceed the peak limit, the battery energy should be saved to use in the future; Contrarily, if the loads won't be greater than the peak, the battery should discharge to cut the cost. Hence, it is vital to predict the situation of the future using previous information. \newline\newline
However, information is time-sensitive which means the information may have lost its original meaning at the present time. For instance, if a customer uses two air conditioners for a week due to the high temperature, which keeps the load high for the previous week. However, after the week the customer decides not to turn on the air conditioners, the load levels will return to normal. Hence, the previous information loses its usage to predict the future. Under such circumstances, the prediction model has to judge whether the information is still valid. Therefore, the first step is to estimate the validity of the information. If the difference between the current load and the previous load at the same time yesterday is greater than a threshold (0.4 $PL$), the previous information is probably no longer usable. Hence, make a prediction based on the current load information.\newline
\[
    Predict(t)= 
\begin{cases}
    \text{Fully Discharge},& \text{if } L_i < 0.5PL\\
    \text{No Charge or Discharge},              & \text{if } L_i > 0.8PL \\
    \text{Limited Discharge},              & \text{otherwise}
\end{cases}
\]\newline
If the current load is far away from the peak limit, then assume the load will keep low in the future for a time. Hence, return a flag that tells the heuristic discharge as much as possible. Similarly, if the current load is close to the peak limit, it is possible that in the future some loads may surpass the peak limit, thus no operation for the battery is allowed. Otherwise, it is hard to predict, consequently, a limited discharge flag is returned to the heuristic.\newline\newline
For the other, the difference between the current load and the previous load is less than this threshold, the information is more likely to be useful to help with prediction. Hence, the next two loads of the previous load are picked. \newline
\[
    Predict(t)= 
\begin{cases}
    \text{No Charge or Discharge}, & \text{if } L_{i-23} > PL \text{ and } L_{i-22} > PL\\
    \text{Fully Discharge}, & \text{else if } L_{i-23}<PL \text{ and } L_{i-22}<PL \\
                            & \text{\quad \quad and } L_i<0.8PL  \\
    \text{Limited Discharge}, & \text{else }\\
    
\end{cases}
\]
\newline

\section{Evaluation}
Due to the need to perform multiple computations using different algorithms and parameters on diverse datasets to facilitate better algorithm comparison and mitigate the impact of errors, significant time investment is required. Hence, the project will only run 20 times for each combination of algorithms, parameters and datasets.
\subsection{Regression Test and T-Test}

The codes for the algorithms will be changed while implementing the approaches or verifying the correctness of the algorithms. Hence, it is necessary to validate the results of the algorithms. However, a global optimal need to be figured out to verify whether the results generated by changed implementation is correct. It is impossible to manually calculate the global optimal for each dataset. Hence, the optimal is determined by comparing the results of two different kind of exact algorithms-MILP and DP. If the results calculated by them are equal, it is assumed that such result is the global optimal. The conclusion is based on the logic that because under the circumstance that the principle, the implementation and parameter settings of the algorithms varies significantly, it is unlikely that two exact algorithms are wrong and generate the same error value. Afterward, according to the global optimal values of different datasets, a preliminary assessment of whether the code modifications have compromised the algorithm can be made after modifying some code in the model. However, this approach can't always determine the global optimal because of the discrete variables existing in the DP which makes the result deviate slightly away from the global optima. Hence, if that happenes and the deviation is very subtle, the result of the MILP will be treated as the global optimal. Otherwise, there must be a bug in one of the algorithms since the gap between discrete variables is also subtle.\newline\newline
For approaches like Rolling Horizon and rule-based heuristic, if their solution is better than the global optimal determined by the two exact algorithms, it is certain that the modifications have caused some issues and need to be fixed. Nonetheless, they are not exact algorithms by themselves, thus, it is nature that they won't generate global optimal values. Consequently, the difficulty to examine the correctness of these algorithms still exists.\newline\newline
Additionally, T-Test will be applied to statically compare the solution quality of each algorithms. T-Test can be used to determine if there is a statistically significant difference between the result and the global optima. Moreover, T-Test are suitable for small sample sizes which is useful when dealing with limited data in this project. If one group of the solutions is proved statistically significant greater than another group's result, the algorithm that group stands for are said to perform better than the another algorithms on specific dataset. Furthermore, the T-Test will only be applied to those non-exact algorithms to verify their solution's quality. 
\subsection{Discrete variables and continuous variables}
The MILP and the Rolling Horizon Approach based on MILP can search the solution in continuous space. On the contrary, the DP and related Rolling approach can only deal with discrete variables since they set different states according to the energy in the battery to enable them to search more solution space. \newline\newline
Consequently, the DP may miss the optimal solution since they can only charge or discharge the exact amount of the energy to or from the battery. Hence, in some situation, the result of DP is slightly worse than the MILP. However, such difference can be ignored and a criteria-success rate-is used to handle this difference.\newline\newline
Additionally, the DP can minimize the difference by increasing the number of states which means making the amount of charge or discharge more precise at each time interval. As a result, it is more likely that the DP can generate the exact same solution as the MILP. Nevertheless, by increasing the number of states, the time complexity will also increase which will reduce the efficiency of calculation. 


\subsection{Model and Data}
The parameter settings of the model and the problem can have a great impact on the result. Furthermore, since BESS control problem is a time series problem, the structure of the data is also vital to the result.
\subsubsection{Parameters}
The parameters of this problem is the constraint and conditions of the model. The battery capacity and its maximum input and output power play a constraint role and limits the charging and discharging behavior of the battery. In this project, to avoid the impact of quantities of parameters to be adjusted on the total number of runs, these parameters value are fixed to a reasonable value. Additionally, except for the parameters of the battery, the tariff structure and its peak limit value are another kinds of parameters of this problem. In reality, the battery's parameters is fixed but not the price structure since the government or corporations will dynamically adjust the price of each time period according to the energy supply and demand situation. However, these parameters are also fixed. Though the tariff structure and peak limit will affect the value of the minimum cost result, it doesn't have a great influence on any of the measuring standard. \newline\newline
Apart from the parameters from the problem, different algorithms also have different hyperparameters that can be tuned. The DP has a hyperparameter-the number of different states $N_3$, which controls the balance between the efficiency and the effectiveness of the algorithm. As the $N_3$ increases, the precision of the result is improved, however, at the cost of the runtime since the algorithms has to traverse more states at each time interval. However, while comparing the performance of different algorithms, this hyperparameter is fixed at a value enabling the result approaching the global optimality as much as possible when keeping the model running efficiently. Otherwise, since there are several approaches related to the DP, the number of different combinations of the algorithms and hyperparameters will increase which is infeasible to generate all the results based on the project progress. \newline\newline
Another kind of approach called Rolling horizon has two hyperparameters $\mu$ and $\varepsilon$. $\mu$ manipulates the window size (the fixed sub-problem size) which stands for how much future information can be used. $\varepsilon$ is the tolerance for the current solution and the model can accept a worsen solution if $\varepsilon$ increases. However, to reduce the runtime of the entire comparison, only the hyperparameter $\mu$ is tuned because the problem studied by this project is a time series problem and the instance shows periodic features. Hence, the size of the window $\mu$ has a greater impact on the solution quality which increases the model's ability to find and exploit this pattern.
\subsubsection{Datasets}
The testing datas  generated from one original large dataset. Though there are gaps in the original dataset, the missing data in question are only for one or multiple periods and their absence does not affect the regularity of the remaining data, even if they are not filled or removed.\newline\newline
Based on the original dataset,  different size of the dataset has been created to test different algorithms' performance on different size of the data. As a consequent, the best approach for small dataset and large dataset will be discussed. There will be 20 different data for each size of the dataset.
\section{Result}
To compare different algorithms in-depth, several criteria has been chosen to evaluate these algorithms-percentages of global optimal, success rate, runtime and memory usage. Furthermore, the performance of thr rolling horizon approach with different hyperparameter $\mu$ will be compared with each other. For each combination of algorithm, hyperparameter and size of the dataset, the algorithm will run twenty times for different data on the same size. When comparing these algorithms, the average of these results will be calculated and used. \newline\newline\noindent
The parameters are set below:
\begin{table}[H]
    \centering
    \begin{tabular}{ |p{3cm}||p{3cm}|}
        \hline
        $B_{max}$ & 1\\
        \hline
        $B_{start}$ &0\\
        \hline
        $Po$ & 0.3\\
        \hline
        $PL$ & 0.08\\
        \hline
        $\mu$ & 48\\
        \hline
        $\varepsilon$ & 0.1\\
        \hline
        $N_3$ & 100/200\\
        \hline
    \end{tabular}
    \caption{The parameter settings}
\end{table}
\noindent For DP and pruned DP, the number of states $N_3$ is set to 200 and for improved rolling DP is set to 100 to reduce the excessive runtime.
\subsection{Percentage of Global Solution Found}
When comparing the percentage of global solution found by the algorithms, only the cost of the solution is exactly same as the global optimal determined by the MILP and the DP can algorithm say that they have found the optimal solution. The percentage of global solution found by the algorithms is calculated by the number of the minimum cost divided by the number of the data at this size. \newline
\begin{figure}[H]
    % \captionsetup[subfigure]{justification=centering}
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width =\textwidth]{DP vs PDP vs RDP global.png}
	\caption{DP, Pruned DP and Improved Rolling DP}
	\label{fig:label1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = \textwidth]{milp vs rMILP global.png}
	\caption{MILP and basic Rolling MILP}
	\label{fig:label2}
	\end{subfigure}
	\hfill\\
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = 1\textwidth]{Rule vs Rule with Prediction global.png}
	\caption{Rule and Rule with Prediction}
	\label{fig:label3}
	\end{subfigure}
\caption{The Percentage of finding global optimal across all algorithms}
\label{fig:label}
\end{figure}
\noindent It is obviously that the MILP can always find the best solution regardless of the size or the data of the dataset according to the figure. For other algorithms, as the size of the data increases, it is hard for them to find the global optimal solution. However, among these algorithms, DP and basic rolling MILP exhibit the best performance in handling increasingly larger datasets. Even if the size of the dataset increases to 10000, the percentage of the found global optimal solution is above 30\%. \newline\newline
Additionally, after applying pruning strategies to the DP, the ability to find the global optimal solution goes down but still performs better than the remaining algorithms. Nevertheless, the improved rolling horizon based on DP is the worst algorithms, even worsen than the rule-based heuristic. The percent of the global optima found by this approach is always less than 10\%, which means that despite of the size of the dataset, the solution found by algorithm deviates from the global optima. \newline\newline
The performance of the rule-based heuristic and the rule with prediction component is roughly the same. However, when the dataset size is small, the prediction component can improve the rule heuristic. When the dataset size grows, the prediction component has a diminishing role to play. 
\subsubsection{T-Test}
The related rolling horizon and rule-based heuristic approaches will be T-tested since they are not exact algorithms and their performance needs to be compared with the global optimal solution to determine whether their solutions differ significantly from the global optimal solution. \newline\newline
The significant level $\alpha$ is the threshold to judge whether the results are statistically significant. According to the customary practice, we selected the commonly used significance level 0.05 as the significance level for this study.\newline\newline
The p value of two-tail t-test is shown below:
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
            &125 & 500 & 1000 & 3000 & 5000 & 10000\\
        \hline
        Improved Rolling DP & 1.97e-4& 6.7e-07&6.27e-6&0.0012&4.1e-5&8.5e-7\\
        \hline
        Basic Rolling MILP & &0.28&0.047&0.11&0.06&0.11\\
        \hline
        Rule& 2.7e-4&0.0014&0.004&0.015&0.001&0.0035\\
        \hline
        Rule with prediction&0.01&0.0018&0.02&0.045&0.0094&0.029\\
        \hline
    \end{tabular}
    \caption{P value for different algorithms on different size of the dataset}
\end{table}
\noindent If the p value shown above is less than 0.05, the solution generated by the algorithm are significantly different from the global optimal. On the contrary, if it is greater than 0.05, the difference is not significant. Hence, the algorithm performs well on th specific dataset.\newline\newline
According to the table above, the basic rolling MILP can generate solutions that is not significantly different from the global optimal on the most scale of the dataset. Hence, it is more likely that given a dataset, the basic rolling horizon based on MILP can generate extremely high quality solutions. 
\subsubsection{Discussion}
The performance of the DP declines as the size of dataset rises, and it is highly likely because the number of discrete variables also increases, which enhances the possibility of missing correct value in continuous space. Moreover, the pruning strategy contribute more to the lost of precision since the pruning strategies may cut off the right path in the DP search tree although it performs worse when considering some constraints. However, since they make decisions based on global information (past and future), they are still able to find many global optimal under some circumstance. \newline\newline
Additionally, the reason why basic rolling MILP, rule-based heuristic, and the rule heuristic with prediction's ability to find the global best is getting weaker, is probably that they make decisions with limited information. Unlike the MILP and DP, the basic rolling approach only utilize the information within the window and the heuristics can only decide based on the current or previous information. The improved rolling horizon based on DP even combines the disadvantage of both rolling and DP, which may further weaken the ability to find the global optimal solution.

\subsection{Success Rate}
If only using the percentage of the found global optimal solution to compare the algorithms ability to generate a high quality solution, it is not reasonable since if an algorithm can always generate a solution nearby to the global optimal, the algorithm is powerful to solve the problem. Hence, some deviations from the global optima is accepted. The threshold is set to 0.5\% which determines the range of the acceptable solution. If the difference between current solution and optimal solution is less than 0.5\% of the optimal value, then it is considered as a success solution. \newline\newline
However, it is important to choose a reasonable threshold, otherwise the result may become nonobjective. In this project the threshold is 0.5\% which means only subtle deviation is allowed. 
\begin{figure}[H]
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width =\textwidth]{DP vs PDP vs RDP success rate.png}
	\caption{DP, Pruned DP and Improved Rolling DP}
	\label{fig:label1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = \textwidth]{basic MILP vs MILP success rate.png}
	\caption{MILP and basic Rolling MILP}
	\label{fig:label2}
	\end{subfigure}
	\hfill\\
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = 1\textwidth]{rule vs rule prediction success rate.png}
	\caption{Rule and Rule with Prediction}
	\label{fig:label3}
	\end{subfigure}
\caption{The success rate across all algorithms}
\label{fig:label}
\end{figure}
\noindent Comparing to the ability to find the exact global optimal, the ability of the DP and basic rolling horizon based on the MILP to find an approximate solution performs as excellent as the MILP. Both of these algorithms's success rate is 100\% regardless of the dataset, which means that given any dataset, these algorithms are more likely to give a near optimal solution. The success rate of the pruned DP fluctuates between 70\% and 90\%, which represents that this approach also has a good ability to find the near optimal solution.\newline\newline
The rule heuristic with prediction component can improve the quality of heuristic solutions, even as the size of the data set increases. Both of the heuristics's performance is relatively stable when searching for a near-optima solution, though it is not as good as the above algorithms.
\subsubsection{Discussion}
The performance of the improved rolling horizon based on the DP is unpredictable because the success rate fluctuates between 0 and 50\%. The performance of this rolling approach is weak at finding a near-optimal solution since its success rate is less than any other algorithms all the time in this experiment. \newline\newline
Since success rate allows subtle deviation from the global optima, the effect of discrete variables diminishes. Hence, the DP and pruned DP perform well according to this criterion. The basic rolling approach based on MILP is for the same reason. However, the improvement to the improved rolling horizon based on the DP is not significant, probably because the number of states explodes which increases the size of search space. Therefore, it magnifies the error caused by discrete variable at each time interval. Furthermore, the deviation caused by the rolling approach also contributes to the situation.\newline\newline
Additionally, the rule-based heuristic performs well on finding near-optima solution mainly because it attempts to avoid breaking the constraint by following the rules. The prediction component makes it easier because it can learn some pattern from past information. Nonetheless, the heuristic only has limited information from past unlike the rolling which can use some future information. Hence, it can hardly detected the relationship of mutual influence between current time and future. Consequently, the above factors may result in the occasional achievement of near-optimal solutions through the rule-based heuristic.
\subsection{Runtime}
\begin{figure}[H]
    % \captionsetup[subfigure]{justification=centering}
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width =\textwidth]{DP vs Pruned DP running time.png}
	\caption{DP, Pruned DP and Improved Rolling DP}
	\label{fig:label1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = \textwidth]{Rule vs Rule with Prediction Running time.png}
	\caption{MILP and basic Rolling MILP}
	\label{fig:label2}
	\end{subfigure}
	\hfill\\
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = 1\textwidth]{basic Rolling MILP vs MILP running time.png}
	\caption{Rule and Rule with Prediction}
	\label{fig:label3}
	\end{subfigure}
\caption{The runtime across all algorithms}
\label{fig:label}
\end{figure}\newpage
\noindent Though the time complexity of the improved rolling horizon based on the DP is $O(\mu N_1N_3N_4)$, the parameters $\mu$, $N_3$ and $N_4$ is fixed which means it is treated as the constant in this project. Hence, as the size of the dataset rises, the running time still increases linearly. However, comparing with other algorithms, the improved rolling approach increases faster. When the size of the dataset is up to 10000, the average runtime of the algorithm is 6 times of the DP.\newline\newline
The pruned DP has reduce the runtime as the size of the dataset increases, though it is not obvious in the figure. However, This is not a significant improvement compared to their large runtimes. When the size reaches 10000, it takes almost 200 second for both algorithms to generate a solution. The basic rolling MILP runs 8 times faster than the DP and pruned DP due to the efficiency of the MILP and the rolling approach. However, when there is not large amount of the data, the basic rolling horizon based on MILP runs faster than the MILP. As the number of data increases, because the MILP increases slower than the basic rolling approach, the MILP become more efficiently than the rolling even 4 times faster. \newline\newline
The most efficient approaches are the rule-based heuristic since it can generate a solution almost instantaneously even the number of data is 10000. Moreover, the prediction component makes the heuristic faster, all the calculation can be finished within 50 milliseconds with prediction. The rule-based heuristic with prediction component can run 400 faster than the MILP which is the most efficient methods among other algorithms. 
\subsubsection{Discussion}
The factors that contributes to the large time complexity of the algorithm have been explained in the \textbf{Implementation} section-the number of states required to be traversed explodes. Additionally, the possible reason that the reduction is not significant after applying pruning strategies to the DP is that the pruning strategies can also impose its own overhead. For instance, it is necessary to judge whether the pruning condition is reached. \newline\newline
Moreover, unlike the algorithms related to the DP, the MILP related algorithms have some techniques like branch and bound methods, which enables the algorithm to reduce the solution space to search. Furthermore, for the result that the basic rolling MILP running slower than MILP as the size increasing, there is currently no definitive explanation available for elucidation. One possible reason is that the the number of constraints in each sub-problems may lead to more calculations, and consequently increases the runtime. \newline\newline
The rule-based heuristic and the rule with prediction only need current information and follow several rules to make decisions, which means there is no need to create and traverse the states or sub-problems and search in the solution space within constraints spending lots of time. Hence, they are the most time-efficient algorithms.
\subsection{Memory Usage}
\begin{figure}[H]
    % \captionsetup[subfigure]{justification=centering}
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width =\textwidth]{DP vs Prune vs Rolling memory.png}
	\caption{DP, Pruned DP and Improved Rolling DP}
	\label{fig:label1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = \textwidth]{basic Rolling MILP vs MILP vs Improved DP memory.png}
	\caption{MILP, basic Rolling MILP and Improved rolling DP}
	\label{fig:label2}
	\end{subfigure}
	\hfill\\
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = 1\textwidth]{Rule vs Rule with Prediction memory.png}
	\caption{Rule and Rule with Prediction}
	\label{fig:label3}
	\end{subfigure}
\caption{The memory usage across all algorithms}
\label{fig:label}
\end{figure}
\noindent As shown in figure, the DP and pruned DP take nearly 200 MB even the dataset is small. When the size of the dataset reaches 10000, they even requires 1 GB of memory. The algorithm requires a significant amount of storage resources, which may impose a substantial burden on the system's storage capacity and performance. However, by applying improved rolling approach, the amount of memory required by the DP drop down to a very flat line due to the characteristic of the rolling approach. \newline\newline
As the number of data rises, the memory used by the MILP also increases linearly. But if the basic rolling is applied, the memory usage of the basic rolling approach will be less than the MILP since the rise in rolling approach has slowed in the figure. Moreover, the improved rolling approach based on DP and basic rolling approach based on MILP occupy a similar amount of space. If the size of the dataset keep increasing, they will take up less space than the MILP according to their trend. \newline\newline
The rule-based heuristic and that heuristic with prediction component 
are the most space-saving algorithms. They requires memory less than 20 MB even if the size of the dataset is at 10000. Furthermore, the trends observed in the data indicate that even with larger datasets, the memory usage will not be significantly increased.
\subsubsection{Discussion}
The reason why DP and pruned DP take up largest space compared to other algorithms is similar to the reason why it takes a longest time to run-the algorithms have to create a large number of states at each time interval to store the solution of sub-problems and be traversed at each time interval. However, for both improved rolling DP and basic rolling MILP, the rolling structure enables them to reuse the space, which means after solving the sub-problem at current window size, the entire data structure can be reused and overwritten by the next sub-problem at next window. Hence, as the number of data increases, the rolling approaches increases slower than the approaches without rolling.\newline\newline
In addition, the algorithms related to the rule-based heuristic use less space for the similar reason why they run faster than other algorithms.

\subsection{Hyperparameter of the Rolling Horizon Approach}
As illustrated in the \textbf{Implementation} section, only the hyperparameter $\mu$ of the rolling horizon approach will be tuned. The model used to test is the improved rolling horizon approach based on the DP. 
\begin{table}[H]
    \centering
    \begin{tabular}{|p{3cm}||p{3cm}|p{3cm}|p{3cm}|}
        \hline
    $\mu$ & \multicolumn{3}{|l|}{Window Size} \\
    \hline
    24 & \multicolumn{3}{|l|}{the window contains half a day's worth of data} \\
    \hline
    48 & \multicolumn{3}{|l|}{the window contains data for a day} \\
    \hline
    336 & \multicolumn{3}{|l|}{the window contains data for a week} \\
    \hline
    1440 & \multicolumn{3}{|l|}{the window contains data for a month} \\
    \hline
    \end{tabular}
    \caption{Value of Hyperparameter}

\end{table}
\noindent Since electricity consumption in daily life is regular which suggests that the load at a specific time interval is likely to be repeated. For instance, if a family turned on the air conditioner yesterday which increases the load, it is more likely that the air conditioner is turned on since the temperature probably wouldn't drop or rise rapidly. Hence, it is possible that the load data will be repeated at this specific time interval. Hence, by adjusting the window size of the rolling approach, the performance can be significantly affected.\newline\newline
The algorithms with different $\mu$ value will be run on the 20 different dataset with the same size 3000. The result of the runtime and memory usage will be averaged to avoid bias.\newline\newline
\noindent As shown in the figure 19, The value of hyperparameter $\mu$ that enables the algorithms to find more near-optima solution is 48. Hence, the data is highly correlated with the data in previous day. On the contrary, the data in previous week or month seems useless observed from the figure, since the success rate is 0 which means the approach is unable to find any near-optima solution under this experiment. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{parameter tuning success rate.png}
    \caption{Success rate of different window size}
\end{figure}
\noindent Additionally, it is important to note that the percentage of finding global optima of all these hyperparameter values is 0. Hence, even if the parameters that make the algorithm perform best are found, the algorithm cannot find the global optimal solution. 
\begin{figure}[H]
    % \captionsetup[subfigure]{lin}
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width =\textwidth]{parameter tuning running time.png}
	\caption{runtime}
	\label{fig:label1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[width = \textwidth]{parameter tuning memory.png}
	\caption{MILP, basic Rolling MILP and Improved rolling DP}
	\label{fig:label2}
	\end{subfigure}
	\hfill
\caption{The runtime and memory usage of different window size}
\label{fig:label}
\end{figure}
\noindent As presented in the figure 20, as the window size of the rolling approach increases, the runtime and memory usage also increases linearly. Because when the size rises, the algorithm have to make decisions based on a larger time range with more states need to be created and traversed in each window. Hence, the $\mu$ value 48 improves the performance of the improved rolling horizon approach most with a shorter runtime and less memory usage. 
\section{Conclusion and Future Direction}
\subsection{Conclusion}
One of the motivations of this paper is to compare all these algorithms in-depth. This project has compared them using four criteria. Hence, the best algorithm varies according to different requirements.\newline\newline
If the runtime or memory usage is the most important properties of the algorithm, then the most excellent algorithm is rule-based heuristic with prediction components. Since algorithms related to the rule-based heuristic all run in a short time-300 times faster than the MILP-and occupy smaller memory-5 times smaller than the MILP or rolling approaches-and the heuristic with prediction can even shorter the runtime and reduce memory usage, it is the best algorithm under this criteria.\newline\newline
Additionally, if only current information is allowed to use (no previous or future information), then only rule-based heuristic can be applied since it makes decisions only using current information. Furthermore, if previous information is allowed, then rule-based heuristic with prediction components performs better with shorter time, better solutions and less memory usage. \newline\newline
However, if the goal of the model is to find the exact global optimal, then MILP is the most suitable algorithm. On the contrary, if the quality of the solution is still significant and only limited future information can be used, then the basic rolling approach based on MILP is the top method. Compared to those methods which can work under the circumstances of limited future information, the basic rolling MILP is more likely to find the near-optima solution than rule-based heuristic. Moreover, the basic version runs 8 times faster than the improved rolling approach DP and use less memory. Hence, basic rolling approach MILP is the best performance method. \newline\newline
Furthermore, since the MILP's related library from IBM is charged, when there is still a need to find an optimal solution or near-optima solution, the DP is the most ideal algorithm. Because the DP is an exact method and it can always find the near-optima solution observed from the result, the DP is the most suitable approach. It is important to note that though the pruned DP can reduce the runtime, the ability to find near-optima solution decreases even faster-the success rate reduces from 100\% to 80\%.


\subsection{Future direction}
There have been many studies on the BESS control problem, while many future work still need to be done. This project only focus on the optimization of the basic BESS problem, the next step can focus in many different directions.\newline\newline
One direction is to include more advanced algorithms or approaches to solve this problem. In the rule-based heuristic, all the prediction is based on current information or limited previous information, but the prediction can still be improved. For example, Autoregressive Integrated Moving Average (Arima)-a time series analysis and forecasting algorithm-can be applied to utilize many past information and capture the short term and long term trend in the data and its seasonal features. After applying more advanced prediction algorithms like Arima, the prediction and the solution quality can be enhanced. Additionally, since only optimization methods are considered in the project, machine learning algorithms can also be included to solve the problem. Many previous work has been done to apply different machine learning algorithms to the BESS problem, however, few work has been done to compare these algorithms and non-machine learning methods in-depth. \newline\newline
Another direction is to extend the current model or build a more complex model. The project only focus on the ideal problem, hence some reality factors are not included. The government and some corporations can adjust the tariff structure based on the power supply and demand level. Hence, the tariff structure is dynamically changed and the implemented algorithms need to adapt or even predict it to improve the solution. Furthermore, the batteries have a life span, and the efficiency of charging and discharging and the capacity of batteries will decrease with the increase of use time. Therefore, the future works can take an effort to study on the decay of the battery. In general, there are many practical factors to consider when working on an extension. Additionally, the export part can be added into the model if the tariff structure and the battery is changing dynamically. Since one of the reasons why business companies and individual customers are interested in the BESS is its ability to connect to the grid and export the energy in the battery into the grid to make a profit, thus the export part in the tariff structure and the export behavior can be designed into the algorithms. \newline\newline
Last but not least, tuning the hyperparameters to find the most general algorithm can be another direction in the future. The project only treat the battery related parameters as fixed parameters, however, after extending the model, different type of batteries and its capacity and the price can be considered. For example, if the capacity of battery is treated as a hyperparameter, the electricity cost decreases since with larger capacity, the model are more flexible to deal with tariff structure. However, the price of battery is increasing and affect the total cost of the solution. Moreover, there are some hyperparameters from different algorithms can also be tuned to improve the efficiency and the effectiveness of the approach. 

\section{Reflections}
\subsection{Project Management}
At the beginning of the project, because I have no knowledge of the entire problem and related algorithms, for each algorithms I allocated a long time to them. For the same reason, I decided to have a meeting with Professor Geert every week to communicate the progress of the project and the problem I encountered. \newline\newline
However, it takes shorter time to understand what the BESS prediction control model is and implement the MILP and DP including some pruning strategies. Hence, I also have done some studies on the Rolling Horizon Approach and implement a simple version of it ahead of the schedule. \newline\newline
When entering the second semester, some issues of the Rolling Horizon approach based on DP happened. Hence, I turned to another method MILP to be the problem-specific algorithm of the Rolling approach. Additionally, I also read some papers about the rule-based heuristic and implemented it. After communicating with professor, I decided to build a prediction component for the rule-based heuristic to improve the quality of the solution. After the prediction model is built and finished the plan made in in interim report, the Professor suggested me to include a more advanced prediction approach. Hence, I read some materials about the Arima-a time series forecasting method-and attempted to implemented it. Nevertheless, because there's not enough time at the end, A full rule-based heuristic with Arima was not completed. Additionally, when trying to include the Arima model, I also attempted to consider the battery degradation in the algorithms and had implemented in the rule-based heuristic. However, other approaches has not included this part for the same reason of time limitation. 
\subsection{Contribution and Reflection}
At the end of the project, I have achieved all the goals listed in my revised plan. At the first semester, I implemented some basic methods-MILP and DP-that has been applied to the BESS problem before. At the second semester, I read some papers and applied some novel methods which has not been applied to the BESS problem in previous works. The rolling horizon approach is built with two algorithms-MILP and DP. Furthermore, the rule-based heuristic also has extra novelty, the prediction component is added into the heuristic which has improved the result. \newline\newline
Additionally, I have compared all these approaches in-depth, which is another novelty of my work. I compared their runtime, memory usage, the percentage of the global solution and success rate. Such comparison has not been done before.
\subsubsection{LSEPI} 
My work doesn't create any intellectual properties and it only focuses on the basic pattern of the BESS problem. Hence, it is more of a theoretical study than a commercial application. Hence, intellectual property is not significant for my project. \newline\newline
Additionally, this work doesn't contain any human participants and data subjects, only the public load data with the time and the meter id. All the privacy has been well protected. Therefore, research ethics is not significant for my project. For the same reason, my work didn't collect or use any personal data, and data protection is not significant for my project either. \newline\newline
Furthermore, this work is not affected by other legislation since it is irrelevant to human rights, security and privacy and it works offline. Hence, other legislation is also not vital to this project.\newline\newline
Last but not least, individual customers and business companies can benefit from the work, because the work focus on solving the BESS control problem effectively and efficiently. The result of the problem can help reduce their electricity cost. It seems that this work will not have intended consequences. If this work continues, then the result of the work can help people reduce their cost and help the government adjust the power. \newline\newline
This work is worth my effort, because for me, I have a deeper understanding of the optimization problem and accumulate experience by practice. For the BESS problem, my work may contribute to the application of the BESS which can both benefit the individuals, society and nature. 

\addcontentsline{toc}{section}{References}
\newpage
\bibliographystyle{plain}
\bibliography{price,energycrisisandprice,instability,newenergy,BESSandCleanEnergy,cheapbattery,UKTimeofuse,WhyTOU,BESSApplication,domestic,grid,ES,whatisbess,bessgrid,BESSIntroduction,functionOfBESS,MILP,DP,prunedDP2,rolling,rule,anotherRule,evaluation,degradationcost,lifecyleDoD,linearDegra}

\end{document}
